Using custom data configuration default-66c04ae0225da417
Downloading data files: 100% 2/2 [00:00<00:00, 1532.73it/s]
Extracting data files: 100% 2/2 [00:00<00:00, 108.14it/s]
100% 2/2 [00:00<00:00, 119.19it/s]
 15% 14007/93161 [00:00<00:02, 27524.24ex/s]
Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-66c04ae0225da417/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...

100% 93161/93161 [00:04<00:00, 20791.39ex/s]
100% 5000/5000 [00:00<00:00, 17762.22ex/s]





















100% 93161/93161 [00:43<00:00, 2119.89ex/s]
100% 1000/1000 [00:00<00:00, 2617.97ex/s]











































































































































































































  0% 274/500000 [06:55<210:28:09,  1.52s/it, epoch=0.172, grad_norm=0.0774, loss=0.687, lr=2.5e-5, samples=16000, step=250, val_ema_loss=0.707, val_loss=0.697]
Traceback (most recent call last):
  File "/content/drive/MyDrive/NLP_PROJECT/latent-diffusion-for-language/train_text_diffusion.py", line 203, in <module>
    main(args)
  File "/content/drive/MyDrive/NLP_PROJECT/latent-diffusion-for-language/train_text_diffusion.py", line 91, in main
    trainer.train()
  File "/content/drive/MyDrive/NLP_PROJECT/latent-diffusion-for-language/diffusion/denoising_diffusion.py", line 703, in train
    self.accelerator.backward(loss)
  File "/usr/local/envs/latent-diffusion/lib/python3.10/site-packages/accelerate/accelerator.py", line 884, in backward
    loss.backward(**kwargs)
  File "/usr/local/envs/latent-diffusion/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/usr/local/envs/latent-diffusion/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt