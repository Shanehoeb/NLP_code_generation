2023-06-19 09:24:33,888 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Configure stats pid to 16311
2023-06-19 09:24:33,890 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Loading settings from /root/.config/wandb/settings
2023-06-19 09:24:33,890 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Loading settings from /content/drive/MyDrive/NLP_PROJECT/latent-diffusion-for-language/wandb/settings
2023-06-19 09:24:33,890 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-06-19 09:24:33,890 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'train_text_diffusion.py', 'program': '/content/drive/MyDrive/NLP_PROJECT/latent-diffusion-for-language/train_text_diffusion.py'}
2023-06-19 09:24:33,890 INFO    MainThread:16311 [wandb_setup.py:_flush():68] Applying login settings: {'mode': 'offline'}
2023-06-19 09:24:33,891 INFO    MainThread:16311 [wandb_init.py:_log_setup():476] Logging user logs to saved_models/codeparrot-clean/2023-06-19_09-24-07/wandb/offline-run-20230619_092433-35h9pu59/logs/debug.log
2023-06-19 09:24:33,892 INFO    MainThread:16311 [wandb_init.py:_log_setup():477] Logging internal logs to saved_models/codeparrot-clean/2023-06-19_09-24-07/wandb/offline-run-20230619_092433-35h9pu59/logs/debug-internal.log
2023-06-19 09:24:33,892 INFO    MainThread:16311 [wandb_init.py:init():516] calling init triggers
2023-06-19 09:24:33,893 INFO    MainThread:16311 [wandb_init.py:init():519] wandb.init called with sweep_config: {}
config: {}
2023-06-19 09:24:33,893 INFO    MainThread:16311 [wandb_init.py:init():569] starting backend
2023-06-19 09:24:33,893 INFO    MainThread:16311 [wandb_init.py:init():573] setting up manager
2023-06-19 09:24:33,900 INFO    MainThread:16311 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-06-19 09:24:33,909 INFO    MainThread:16311 [wandb_init.py:init():580] backend started and connected
2023-06-19 09:24:33,915 INFO    MainThread:16311 [wandb_init.py:init():658] updated telemetry
2023-06-19 09:24:33,921 INFO    MainThread:16311 [wandb_init.py:init():728] starting run threads in backend
2023-06-19 09:24:38,236 INFO    MainThread:16311 [wandb_run.py:_console_start():1980] atexit reg
2023-06-19 09:24:38,236 INFO    MainThread:16311 [wandb_run.py:_redirect():1838] redirect: SettingsConsole.WRAP_RAW
2023-06-19 09:24:38,237 INFO    MainThread:16311 [wandb_run.py:_redirect():1903] Wrapping output streams.
2023-06-19 09:24:38,237 INFO    MainThread:16311 [wandb_run.py:_redirect():1925] Redirects installed.
2023-06-19 09:24:38,238 INFO    MainThread:16311 [wandb_init.py:init():765] run started, returning control to user process
2023-06-19 09:24:38,253 INFO    MainThread:16311 [wandb_run.py:_config_callback():1160] config_cb None None {'dataset_name': 'codeparrot-clean', 'save_dir': 'saved_models', 'output_dir': 'saved_models/codeparrot-clean/2023-06-19_09-24-07', 'wandb_name': None, 'corruption_prob': 0.0, 'train_batch_size': 64, 'eval_batch_size': 32, 'num_train_steps': 500000, 'gradient_accumulation_steps': 1, 'learning_rate': 0.0001, 'lr_schedule': 'cosine', 'lr_warmup_steps': 1000, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 1e-06, 'ema_decay': 0.9999, 'ema_update_every': 1, 'objective': 'pred_x0', 'loss_type': 'l1', 'beta_schedule': 'linear', 'p2_loss_weight_gamma': 0, 'timesteps': 1000, 'sampling_timesteps': 250, 'normalize_latent': True, 'save_and_sample_every': 5000, 'num_samples': 1000, 'self_condition': True, 'ddim_sampling_eta': 1, 'enc_dec_model': 'facebook/bart-base', 'tx_dim': 768, 'tx_depth': 12, 'scale_shift': True, 'disable_dropout': True, 'class_conditional': False, 'class_unconditional_prob': 0.1, 'amp': False, 'mixed_precision': 'no', 'eval': False, 'eval_test': False, 'resume_training': False, 'gen_data': False, 'resume_dir': None, 'milestone': 12, 'trainable_params': 214342272}
